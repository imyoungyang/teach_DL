{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn in /opt/conda/lib/python3.6/site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.6/site-packages (from sklearn) (0.20.0)\n",
      "Requirement already satisfied: numpy>=1.8.2 in /opt/conda/lib/python3.6/site-packages (from scikit-learn->sklearn) (1.15.0)\n",
      "Requirement already satisfied: scipy>=0.13.3 in /opt/conda/lib/python3.6/site-packages (from scikit-learn->sklearn) (1.1.0)\n",
      "\u001b[33mYou are using pip version 18.0, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import k3d\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn import datasets\n",
    "from sklearn.cluster import DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define number of points in [generated] dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nSamples = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Available SkLearn Datasets \n",
    "feel free to comment out unused datasets to reduce memory overhead [ especially for  large nSamples ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "swissRollX = datasets.make_swiss_roll( n_samples=nSamples, noise=0.0, random_state=0)[0]\n",
    "# http://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_swiss_roll.html\n",
    "\n",
    "blobsX, blobsY = datasets.make_blobs(n_samples=nSamples, centers=4, n_features=3, cluster_std=0.4, random_state=0)\n",
    "\n",
    "noisyMoonsX = datasets.make_moons(n_samples=nSamples, noise=.005)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Dataset(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def viz_dataset( dataset ):\n",
    "    assert( dataset.shape[1] == 3)    \n",
    "    \n",
    "    plot = k3d.plot()\n",
    "    \n",
    "    plot += k3d.points ( dataset, color=0xFF00FF, point_size = .3, shader = 'flat' )        \n",
    "    \n",
    "    plot.display()\n",
    "    \n",
    "def make_3dimensional(dataset):\n",
    "    if dataset.shape[1] == 2:\n",
    "        print('        > add empty third dimension to 2d dataset')\n",
    "        dataset = np.hstack([dataset, np.zeros((dataset.shape[0],1))])\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        > add empty third dimension to 2d dataset\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d257095593024a9796eb2ad6a012d4ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# moons \n",
    "dataset = make_3dimensional ( noisyMoonsX )\n",
    "viz_dataset( dataset )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f84c95133ed64e2c831617ea3f45f3d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# blobs \n",
    "dataset = make_3dimensional ( blobsX )\n",
    "viz_dataset( dataset )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "451b4c4d07524d69be315c3e585815d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# swiss roll\n",
    "dataset = make_3dimensional ( swissRollX )\n",
    "viz_dataset( dataset )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Plot labels [ i.e. model cluster predictions ] as color overlays onto dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cluster_predictions ( dataset, labels ):\n",
    "\n",
    "    labelSet = set(labels)\n",
    "    print(labelSet)\n",
    "    nClusters = len(labelSet)\n",
    "    print( 'predicted nClusters = ' + str(nClusters) + ' [ from ' + str(nSamples) + ' samples ]')\n",
    "\n",
    "    # generate nCluster random colors\n",
    "    np.random.seed(0)\n",
    "    colors = np.random.randint(0, 0xFFFFFF, nClusters)\n",
    "    plot = k3d.plot()\n",
    "\n",
    "    for iCluster in range(nClusters):\n",
    "        \n",
    "        clusterID = list(labelSet)[iCluster]\n",
    "        clusterInds = np.where(labels == list(labelSet)[iCluster])[0]\n",
    "        print(str(iCluster) + ' : ' + str(len(clusterInds)))\n",
    "        plot += k3d.points ( dataset[clusterInds, :], color=int(colors[iCluster]), point_size = .075, shader = 'flat' )\n",
    "        \n",
    "    plot.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DBScan @ Blobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 1, 2, 3}\n",
      "predicted nClusters = 4 [ from 1000 samples ]\n",
      "0 : 250\n",
      "1 : 250\n",
      "2 : 250\n",
      "3 : 250\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e28df2e6a694519899e202422a31939",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = make_3dimensional ( blobsX ) # ensure dataset has 3 dimensions [ padding if necessary ]\n",
    "dataset = sklearn.preprocessing.StandardScaler().fit_transform(dataset) # normalize\n",
    "\n",
    "dbScanModel = DBSCAN().fit(dataset)\n",
    "labels = dbScanModel.labels_\n",
    "\n",
    "plot_cluster_predictions ( dataset, labels )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DBScan @ Swiss Roll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0}\n",
      "predicted nClusters = 1 [ from 1000 samples ]\n",
      "0 : 1000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "281b71d366fc48c2b34c25b062d3bddb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = make_3dimensional ( swissRollX ) # ensure dataset has 3 dimensions [ padding if necessary ]\n",
    "dataset = sklearn.preprocessing.StandardScaler().fit_transform(dataset) # normalize\n",
    "\n",
    "dbScanModel = DBSCAN().fit(dataset)\n",
    "labels = dbScanModel.labels_\n",
    "\n",
    "plot_cluster_predictions ( dataset, labels )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DBScan @ Noisy Moons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        > add empty third dimension to 2d dataset\n",
      "{0, 1}\n",
      "predicted nClusters = 2 [ from 1000 samples ]\n",
      "0 : 500\n",
      "1 : 500\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8826f5bca5e84b589cbdbc14d14b3d86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = make_3dimensional ( noisyMoonsX ) # ensure dataset has 3 dimensions [ padding if necessary ]\n",
    "dataset = sklearn.preprocessing.StandardScaler().fit_transform(dataset) # normalize\n",
    "    \n",
    "dbScanModel = DBSCAN().fit(dataset)\n",
    "labels = dbScanModel.labels_\n",
    "\n",
    "plot_cluster_predictions ( dataset, labels )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Init signature: DBSCAN(eps=0.5, min_samples=5, metric='euclidean', metric_params=None, algorithm='auto', leaf_size=30, p=None, n_jobs=None)\n",
    "\n",
    "Docstring:     \n",
    "Perform DBSCAN clustering from vector array or distance matrix.\n",
    "\n",
    "DBSCAN - Density-Based Spatial Clustering of Applications with Noise.\n",
    "Finds core samples of high density and expands clusters from them.\n",
    "Good for data which contains clusters of similar density.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "eps : float, optional\n",
    "    The maximum distance between two samples for them to be considered\n",
    "    as in the same neighborhood.\n",
    "\n",
    "min_samples : int, optional\n",
    "    The number of samples (or total weight) in a neighborhood for a point\n",
    "    to be considered as a core point. This includes the point itself.\n",
    "\n",
    "metric : string, or callable\n",
    "    The metric to use when calculating distance between instances in a\n",
    "    feature array. If metric is a string or callable, it must be one of\n",
    "    the options allowed by :func:`sklearn.metrics.pairwise_distances` for\n",
    "    its metric parameter.\n",
    "    If metric is \"precomputed\", X is assumed to be a distance matrix and\n",
    "    must be square. X may be a sparse matrix, in which case only \"nonzero\"\n",
    "    elements may be considered neighbors for DBSCAN.\n",
    "\n",
    "    .. versionadded:: 0.17\n",
    "       metric *precomputed* to accept precomputed sparse matrix.\n",
    "\n",
    "metric_params : dict, optional\n",
    "    Additional keyword arguments for the metric function.\n",
    "\n",
    "    .. versionadded:: 0.19\n",
    "\n",
    "algorithm : {'auto', 'ball_tree', 'kd_tree', 'brute'}, optional\n",
    "    The algorithm to be used by the NearestNeighbors module\n",
    "    to compute pointwise distances and find nearest neighbors.\n",
    "    See NearestNeighbors module documentation for details.\n",
    "\n",
    "leaf_size : int, optional (default = 30)\n",
    "    Leaf size passed to BallTree or cKDTree. This can affect the speed\n",
    "    of the construction and query, as well as the memory required\n",
    "    to store the tree. The optimal value depends\n",
    "    on the nature of the problem.\n",
    "\n",
    "p : float, optional\n",
    "    The power of the Minkowski metric to be used to calculate distance\n",
    "    between points.\n",
    "\n",
    "n_jobs : int or None, optional (default=None)\n",
    "    The number of parallel jobs to run.\n",
    "    ``None`` means 1 unless in a :obj:`joblib.parallel_backend` contex\n",
    "    \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
